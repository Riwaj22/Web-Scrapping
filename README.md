# Web-Scrapping

Project1: Scrapping Multiple webpages from a website

Description: Website used for scrapping is audible.com and data such as author name, runtime, book name were scrapped and stored in csv file which then can be used for preparing ml models.Library used is selenium.

Website used: www.audible.com/search

Project 2: Use of selenium to scrap and capture information from twitter from infinite number of pages allowing to prepare a dataset containing user name and their tweet which can be further processed for applying NLP

Website used: www.twitter.com



Libraries Used:

1. Beautiful Soup is a Python library used for parsing HTML and XML documents. It allows you to extract data from web pages by navigating the document's structure. In the context of machine learning (ML), Beautiful Soup can be used for data collection, preprocessing, feature extraction, and labeling/annotation tasks. It helps in scraping web data, cleaning and transforming it, extracting relevant features, and facilitating the manual labeling of data for ML models.

2. Selenium: Selenium is a widely used tool for web scraping, which involves extracting data from websites. It allows for web browser automation, enabling you to interact with web pages, locate specific elements, extract data, navigate through multiple pages, and process the scraped data as needed\

3. Scrapy:  With Scrapy, we can define spiders that specify how to navigate through web pages, follow links, and extract specific information using XPath or CSS selectors. Scrapy offers features such as automatic request throttling, cookie and session handling, concurrent requests, and support for various data storage formats. It provides a command-line interface for managing and running scraping projects, and allows you to process and store the extracted data using item pipelines. Scrapy is scalable, efficient, and offers extensions and integrations to enhance its functionality. It is widely used for scraping websites and extracting data for various purposes.
